# 1. Introducing Core Image
## Introduction
- iOS 9 이상부터.
- `Core Image` iOS나 OS X에서 이미지를 분석하거나 processing할 때 사용되는 프레임워크.


## Core Image Fundamentals
### Core Image Context, `CIContext`
```swift
let context = CIContext()
```
- 위의 케이스는 CPU 베이스의 배경으로 GPU보다는 느리다. 그러므로 하나의 이미지 변환시 사용하는건 문제 없지만 라이브 비디오처럼 즉각적으로 복수의 이미지들이 변환되어야 하는 상황에서는 빠르지 않다.
- 즉, 더 나은 퍼모먼스가 필요하면 GPU 기반의 `EAGL(OpenGL for Embedded Systems) context, = GLKit`를 만들어서 사용해야한다.
- `GLKit`을 사용하면 GPU에서 CIImage 프로세싱과 CPU없이 view의 buffer frame에 바로 CIImage를 그릴 수 있다.


```swift
//EAGL 사용

let eaglContext = EAGLContext(API: .OpenGLES2)
let context = CIContext(EAGLContext: eaglContext)
```

- 만약 위를 사용하는 상황보다 더 큰 퍼포먼스를 사용하게 되면, 아래 예제처럼 `kCIContextWorkingColorSpace`에서 옵션을 `null`로 함으로써 color management를 끌 수 있다.

```swift
let context = CIContext(EAGLContext: eaglContext, 
                        options: [KCIContextWorkingColorSpace: NSNull()])
```

### Core Image Filter, `CIImage`
- 인스턴스로 `CIFilter`
- `setValue()`로 함께 설정된다.

```swift
let blurFilter = CIFilter(name: "CIGaussianBlur")!

blurFilter.setValue(ciImage, forKey: kCIInputImageKey)
blurFilter.setVlaue(25, forKey: kCIInputRadiusKey)
```

- filter의 output은 두가지로 접근할 수 있다. 

```swift
//1. AnyObject로 일반적으로는 CIImage로 반환된다.
let result = blurFilter.valueForKey(kCIOutputImageKey)

//2. optional CIImage로 반환된다.
let result = blurFilter.outputImage
```

- 중복적으로 filter를 적용할 때는 우선적으로 적용된 filter의 output을 바로 두번째로 적용할 필터의 input으로 적용시킨다.

```swift
let hueAdjust = CIFilter(name: "CIHueAdjust",
					withInputPrameters: [kCIInputAngleKey: 3.14,
											kCIOutputImageKey: blurFilter.outputImage!])
```

### Core Image, `CIImage`
- Core Image는 `CIImage`라는 자신만의 데이터 타입을 갖고있다.
- 비트맵을 가지지 않는다. (=View에 UIImage로 바로 적용 불가능.)
- CIFIlter에서 output, input으로 사용되고 output으로 사용될땐 UIImage와 같이 직접적으로 사용할 수 있는 포맷으로 변경도 가능하다. 이 경우엔 다른 포맷으로 변경하는 것까지 filter가 다 수행한다.

```swift
//UIImage > CIImage
let uiImage = UIImage(named: "flower.jpg")
let ciImage = CIImage(image: uiImage!)
```

- 반대로 CIImage가 UIImage로 보여질 수 있다.
```swift
//CIImage > UIImage
let uiImage = UIImage(CIImage: ciImage)
```

- CIImage에 컬러링을 할 수도 있다. `init(color:)`
```swift
let brownImage = CIImage(color: CIColor(red:0.6, green:0.6, blue:0.2))
```

- live video를 filter로 사용할 때에는 `pixel buffer`로부터 CIImage를 만들어서 사용해야한다. `init(CVPixelBuffer:)`

```swift
let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer)
let ciImage = CIImage(CVPixelBuffer: pixelBuffer!)
```

- CIImage도 필터를통해 새로운 이미지를 만드는 메소드들의 handy set을 가진다. 예를 들어 output을 변수를 지정하고 또 다른 filtered image 변수에 지정해 주는 것이 아니라 `imageByApplyingFilter():`로 filteredImage에 바로 적용할 수 있다. 같은 방법으로 `CICrop`도 `imageByCroppingToRect()`로 생략해 사용할 수 있다.

```swift
////output
//no handy set
let filter = CIFilter(name: "CISepiaTone", withInputParameters: [kCIInputImageKey: image, kCIInputIntensityKey: 0.5])])
let filteredImage = filter?.outputImage

//use handy set
let filteredImage = image.imageByApplyingFilter("CISepiaTone", withInputParameters: [kCIInputIntensityKey: 0.5])

////crop
//use handy set
let rect = CGRect(x: 0, y: 0, width: 640, height: 480)
let croppedImage = image.imageByCroppingToRect(rect)
```

### Core Image Kernel, `CIKernel`
- Core Image의 shader laguage에 쓰여져 기능을 필터의 기능을 구성한다.
- 모든 Core Image 필터는 적어도 하나의 kernel을 가지고 있고 2개 이상일 수도 있다.
- Kernel의 3가지 카테고리.
	1. Color Kernel : 각각 픽셀의 색을 변경하는 것을 간단하게 효과적으로 한다.
	2. Warp Kernel : 이미지를 기하학적으로 변경하는 것을 효과적으로 한다. 크기조정이나 자르기.
	3. General Kernel : 이미지에서 Color picwel에서 하지못한 다양한 픽셀들을 시험한다. 블러 또는 sharpening filter에 사용된다.


> [앞으로의 참고 Github](https://github.com/FlexMonkey/CoreImageForSwiftPlaygrounds)