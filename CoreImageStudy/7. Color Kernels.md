# 7. Color Kernels

- 색 정보들을 관리.

## Creating a Threshold Filter
- 🤧 나의 정리 🤧 : threshold Filter는 rgb값을 계산으로 빛의 단위인 float 값인 luma를 계산하고 그 계산값에 따라 밝은 부분은 흰색으로 어두운 부부은 검은색인 이미지로 리턴된다. 밝은 부분을 표시할 정도를 kCIInputParameter 중 inputThreshold에서 정의해준다. 

#### Calculating Threshold, 기준치 계산하기
- RGB color에서 밝기를 계산하는 방법을 사용한다. `luma = (red * 0.2126)+(green * 0.7152)+(blue * 0.0722)`
- green은 밝음으로 blue는 어두움으로 인식한다.

#### The Kernel Code
- Color Kernel이 때에 적당한 픽셀에 필요한 것과 어떠한 주변픽셀의 값을 신경쓰지않기 시작한 후부터, CIColorKernel을 새로 창작하는 이 필터에 사용할 수 있다.
- 이미지에 작용하는 대신에 Color kernel은 적어도 하나, 하나의 픽셀의 색을 갖고 있는 `__sample` 타입의 argument가 필요하다. 그리고 기준치 값인 `threshold`라고 부르는  `float(숫자)`에서 지나갈 것이다.

	`kernel vec4 thresholdFilter(__sample pixel, float threshold)`
- 함수 안쪽에서, pixel의 색 값에 기반을 둔  `luma`를 만드는데 공식을 사용할 수 있다. `sample` type은 `vec4-`와 비슷하다. 각각의 x, y, z, w의 color components에 접근할 수 있다. 하지만 색에 제공된 후부터 r,g,b,a와 red, blue, green에 접근하는 것은 더 명백해 졌다.

	`float luma = (pixel.r * 0.2126) + (pixel.g * 0.7152) + (pixel.b * 0.0722); `
	
- 위의 계산은 두 벡터의 doc product를 반환하는 `dot()` 함수가 사용되었다. dot product는 각각의 하나의 벡터에서 두번째 벡터의 같은 위치의 아이템으로부터 증가된 아이템의 합이다.
- 만약 3개의 색에서 빛 값의 두번째 벡터를 만들 수 있다면, `dot()`을 사용하면 return은 아래와 같다.

	`float luma = dot(pixel.rgb, vec3(0.2126, 0.7152, 0.0722));`
	
- 이 경우에서, alpha값은 관계하고 있지 않다. 그래서 3개의 component vector인 `vec3` orginal pixel color인 red, green, blue로 부터 만들었다.
- 아래의 마지막 함수 코드 한 줄은 받아온 값의 리턴을 white로 할지 black으로 할지 결정하는데 사용한다.

	`return (luma>threshold) ? vec(1.0, 1.0, 1.0, 1.0) : vec4(0.0, 0.0, 0.0, 0.0);`

#### Eliminating Branching with step(), `step()`으로 Branching을 제거하기.
- (luma > threshold)의 과정이 3차원일지라도, kernel code의 퍼포먼스를 충돌 시킬 수 있는 `branching`을 소개한다.
- GPS는 병렬(동시의 수행하는 의미)에서 다양한 kernel들을 실행하지만, `wavefront`와 같은 것으로 함께 잠겨져 있다. 
- 다른 branch들에서 사용되는 다양한 kernel들을 가지면서, 예를 들어 `if문`은 wavefront가 완성되기 전 모든 병렬의 kernel은 두개의 brance 모두 실행되는 것을 기다리는 것을 의미한다. ??????????
- 이것을 병렬시 재베치 되는것으로부터 `step()` 함수로 극복할 수 있다.
- `step()`은 두개의 argument를 받아들인다. 하나는 edge, 다른 하나는 edge에 반대로 비교되는 값이다. 값(value)이 edge보다 작다면 `step()`은 0으로 반환되고, edge보다 값이 크면 `step()`은 1을 반환한다. 필터의 이미지 픽셀 리턴이 black인지 white인지 나타내는 `vec4`을 구성하는 값을 리턴하는 것에 사용할 수 있다.

	`return vec4(step(threshold, luma));`
	
- vec4는 single float과 함께 구성 될 수 있다. In this case that value populates all four of its components.


#### Wrapping in a Core Image Filter
- custom filter를 수행하는데에 `CIFilter`를 확장할 수 있고, custom threshold filter를 만드는데에 비슷한 접근을 사용할 것이다.
- 😀 첫 번째 단계, `ThresholdFilter` 이름의 `CIFilter`를 상속받는 새로운 class를 만들기. `inputImage`, `inputThresohld` 2개의 property를 만든다.

	```swift
	class ThresholdFilter: CIFilter :
	
		var inputImage:CIImage?
		var inputThreshold:CGFloat = 0.75
		
		//😀 kernel만들기, CIColorKernel을 만들고 GLSL 코드로 작성한다.
		let thresholdKernel = CIColorKernel(string:
													"kernel vec4 thresholdFilter(__sample pixel, float threshold)" +
													{ " +
													"	float luma = (pixel.r * 0.2126) + " +
													"		(pixel.g*0.7152) + " +
													"		(pixel.b*0.0722); " +
													"	return vec4(step(threshold, luma)); " +
													"}				"
											) 
	
		//불행히도 이 string 문장 후에, runtime까지 코드에 어떤 문제가 있다면 알게 될 것이다.
		//filter의 outputImage가 의문을 품게 될 때, kernel을 적용할 것이다. CIColorKernel의 경우에는 간단하게 되지 않았었다.											//첫 번째 단계는 두개의 optional property가 값을 가지는 것을 확실하게 하는데에 guard 문을 사용하는 것이다.
		//kernel을 컴파일하고 CIImage 그리는 함수는 💡 `applyWithExtent`이다.	
			// > 예) 필터에 전체 이미지에 적용하기.
			//		first argument와 같은 input image의 크기와 2개의 kernel function parameter를 갖고 있는 array를 지나간다.
		
		override var outputImage : CIImage! {
		
			guard let inputImage = inputImage, thresholdKernel = thresholdKernel else {
			
				return nil
				
			}
			
			let extent = inputImage.extent 
			let argument = [inputImage, inputThreshold]
			
			return thresholdKernel.applyWithExtent(extent, arguments: arguments)
		
		}
		
		
		//새로운 threshold filter는 사용될 수 있다. 😀 필터 등록하기.
		CIFilter.registerFilterName("ThresholdFilter", constructor: CustomFiltersVendor(), classAttributes: [kCIAttributeFilterCategories: [CategoryCustomFilters]])
		
		case "ThresholdFilter": return ThresholdFilter()
		
		//😀 사용하는 방법 1. 다른 필터처럼 끄집어내서 사용하기.
		let thresholdFilter = CIFilter(name: "ThresholdFilter", withInputParameters: [kCIInputImageKey: image, "inputThreshold": 0.8])
		
		//😀 사용하는 방법 2. property로 접근해서 사용하기.
		let thresholdFilter = ThresholdFilter()
		thresholdFilter.inputImage = image
		thresholdFilter.inputThresholdFilter()
		
	}
	```

#### Creating a Starburst Filter
- threshold filter는 많은 사용이 되지 않을 수 있다. 하지만 다른 필터와 결합하면, 빛에 따른 효과를 선택적으로 적용하게 되므로 유용해진다.

	- 예. 백열광은 이미지의 가장 밝은 영역으로 골라내고 키라키라와 같은 효과를 주기.
		
		```swift
			let candlesImage = CIImage(image: UIImage(named: "candles.jpg")!)!
			let thresholdImage = candlesImage.imageByApplyingFilter("ThresholdFilter", withInputParameters: ["inputThreshold": 0.9])
			
			//2개의 motion blur 적용하기. 하나는 45도, 하나는 135도.
			let blurImageOne = thresholdImage.imageByApplyingFilter("CIMotionBlur", withInputParameters: [kCIInputRadiusKey: 30, kCIInputAngleKey: M_PI_4]).imageByCroppingToRect(candlesImage.extent)
			let cropRect = candlesImage.extent
			let blurImageTwo = thresholdImage.imageByApplyingFilter("CIMotionBlur", withInputParameters: [kCIInputRadiusKey: 30, kCIInputAngleKey: M_PI_4 + M_PI_2]).imageByCroppingToRect(candleImage.extent)
			
			//2개의 적용된 이미지들을 합치면 빛나는 것처럼 효과가 된다.
			let starBurstImage = blurImageOne.imageByApplyingFilter("CIAdditionCompositing", withInputParameters: [kCIInputBackgroundImageKey: blurImageTwo])
			
			//원본 이미지에 반짝반짝한 것을 합친다.
			let finalCompositeImage = candlesImage.imageByApplyingFilter("CIAdditionCompositing", withInputParameters: [kCIInputBackgroundImageKey: starBurstImage])
		```
		
		- 위와 같은 효과도 다른 코드로 구현.
		
		```swift
			let starBurstAccumulator = CIImageAccumulator(extent: thresholdImage.extent, format: kCIformatARGB8)
			
			for i in 0..< inputBeamCount {
			
				let angle = CGFloat((M_PI/Double(inputBeamCount))*Double(i))
				
				let starburst = thresholdImage.imageByApplyingFilter("CIMotionBlur", withInputParameters: [kCIInputRadiusKey: inputRadius, kCIInputAngleKey: inputAngle + angle]).imageByCroppingToRect(thresholdImage.extent).imageByApplyingFilter("CIAdditionCompositing", withInputParameters: [kCIInputBackgroundImageKey: starBurstAccumulator.image()])
				
				starBurstAccumulator.setImage(starburst)
			
			}
		```

## Shaded Tile Effect
#### Technique
- `tileSize` argument를 받아들이고, 이것을 modulo operator에 로그 계수처럼 사용한다.
- 결과는 tile size에 따라 나뉘어고 제거된다.

`let brightnessMultiplier = 1.0 - (x % tileSize) / tileSize`

#### The Kernel Code
- our shadr에서 GLSL code는 x, y 좌표의 빛에 기초를 둔 modulo를 계산할 수 있다.
- current pixel의 좌표를 얻기 위해서는, x, y값이 있는 `vec2`를 return하는 `samplerCoord()` 함수를 사용할 것이다.

	```swift
	kernel vec4 thresholdFilter(__sample pixel, float tileSize){
		vec2 coord = samplerCoord(pixel);
		float brightness = mod(coord.y, tileSize)/tileSize;
		brightness *= 1.0 - mod(coord.x, tileSize)/tileSize;
		return vec4(brightness*(pixel.rgb), image.a);
	}
	```	
	- 💡 GLSL은 %(나머지)를 지원하지 않기때문에 `mod()`함수를 사용했다.

#### Wrapping in a Core Image Filter

```swift
class ShadedTileFilter: CIFilter {

	var inputImage: CIImage?
	var inputTileSize: CGFloat = 100
	
	override func setDefaults(){
		inputTileSize = 100
	}
	
	var kernel = CIColorKernel(string:
										"kernel vec4 thresholdFilter(__sample pixel, float tileSize)" +
										"{" +
										"	vec2 coord = samplerCoord(pixel); " +
										"	float brightness = mod(coord.y, tileSize)/tileSize; " +
										"	brightness *= 1.0 _ mod(coord.x, tileSize)/tileSize; " +
										"	return vec4(brightness * (pixel), image.a);"
										"}"
								)
	//outputImage getter를 override하는 것. kernel은 input image, input tile size 요구한다. 그래서 요구하는 것들을 array에 넣어준당
	
	override var outputImage: CIImage! {
	
		guard let inputImage = inputImage, kernel = kernel else {
			return nil
		}
		
		let extent = inputImage.extent
		let arguments = [inputImage, inputTileSize]
		
		return kernel.applyingExtent(extent, argumetns: arguments)
	
	}

}
```


## CRT Shadow Mask Filter
- 🤧 나의 정리 🤧 :
- 어떠한 다른 픽셀의 지식 없이 current pixel의 색을 조작하는 것이 디자인되었다.
- color kernel의 대표적인 작업은 color image를 단색화(monochrome)화 하거나 이미지의 밝기나 대조를 변경될 수 있다는 것이다.

#### CRT Screen Filter

#### The Kernel Code
- `CIColorKernel`이 `__sample` 타입의 single pixel을 지나칠 때, Recall된다.
- argument에서 형광체의 width(=`phosphorWidth`)와 scan line의 height(= `scanlineHeight`)가 정의된 kernel code로 지나가길 원한다. kernel이 4가지 size의 vector을 리턴시킨 후, 코드의 첫줄은 아래와 같다.

	```swift
	kernel vec4 crtColor(__sample pixel,
		float phosphorWidth,
		float scanlineHeight) {
	```
	
- kernel의 첫번째 일은 0 ~ 2 범위에서 coloring에 사용될 column index를 계산하는 것이다. 계산된 값으로 pixel의 가로로 가로 좌표를 나누는 것과 3의 modulus와 modulo operator를 적용하는 것, 두 가지를 할 수 있다.

	```swift
	int columnIndex = int(
	
		mod(samplerCoord(pixel).x / phosphorWidth, 3.0)
	
	);
	```
- scan line을 coloring하는데 사용될 row index를 계산하는 데에 비슷한 순서로 사용한다. 하지만 이때 `pixelHeight`의 modulus를 사용함. ????????????????

	```swift
	int rowIndex = int(
		mod(samplerCoord(pixel).y, scanlineHeight)
	);
	```

- row index와 함께, 첫 번째의 두개의 줄의 모든 `pixelHeight`를 희미하게 할 다른 변수(=`scanlineMultipler`)를 만드는데에 3개로 이루어진 operator를 사용할 수 있다. ???????????

	```swift
	float  scanlineMultiplier = (rowIndex == 0 || rowIndex == 1)?
		0.3:
		1.0;
	```
p. 142 🐞🐞🐞🐞🐞🐞🐞🐞🐞🐞🐞🐞🐞🐞🐞🐞🐞🐞🐞
[link](https://github.com/FlexMonkey/Filterpedia/blob/master/Filterpedia/customFilters/CRTFilter.swift)

#### Wrapping in a Core Image Filter

## Simulating VHS Tracing Lines
- 이 필터는 time based이고, input time parameter를 노출시킨다.

#### Creating an Animated Noise Field
- Core Image의 noise image를 발생시키는 `CIRandomGenerator`를 사용한다. 
- 시간이 지남에 따라 noise가 변화하길 원하는데 `CIRandomGenerator`는 항상 같은 output으로 반환된다. 그리고 가로 줄이 있는 걸 원한다.
- 시간에 따라 변화하는 noise 영역 만들기! 간단하게 random position으로 움직일 수 있다. random 발생 영역이 한없이 큰 이미지에 만들어진 후에, source image 위에서 효과적으로 움직임을 변화시키면 된다.

```swift
	//😀 `tx`라는 random x, y를 constant를 만든다. 
	let tx = NSValue(CGAffineTransform: CGAffineTransformMakeTranslation(CGFloat(drand48()*100), CGFloat(drand48()*100)))
	
	//😀 지지직거림은 `CILanczosScaleTransform` 필터의 aspect ratio 5로 적용된다.
	// random generator, affine transform, Lanczos scale은 아래의 코드로 적용된다.
	let noise = CIFilter(name: "CIRandomGenerator")!.outputImage!.imageByApplyingFilter("CIAffineTransform", withInputParameters: [kCIInputTransformKey: tx]).imageByApplyingFilter("CILanszosScaleTrnasform", withInputParameters: [kCIInputAspectRatioKey: 5]).imageByCroppingToRect(inputImage.extent)
```

#### Creating the Tracking Lines Kernel, 가로줄 필터 만들기
- 필터의 input image의 속에, kernel을 통해서 만든 noise image가 지나갈 것이다.
- 또한 kernel은 줄무늬 noise를 animated하는데에 time parameter가 필요하고, stripe의 width와 spacing을 control할 추가적인 parameter를 제공할 것이다.
- 아래의 코드는 `vhsTrackingLines`의 함수를 선언한 것이다.

	```swift
	kernel vec4 vhsTrackingLines(__sample image, __sample noise, float time, float spacing, float stripeHeight, float backgroundNoise)
	```	
	
- stripe의 위치는 계산된 pixel의 세로 위치에 의존한다. kernel function의 첫번째 단계는 y의 위치 변수를 정하는 것이다.

	`float y = samplerCoord(image).y;`

- current time에 추가된 y의 사인(사인, 코사인, 탄젠트 중의 사인!)을 가질 것이다. spacing도 나눌 것이다.
- bar의 두께를 control하는 것. `smoothstep()` function 속의 값을 지나갈 것이다. `smoothstep()`은 나중에 뒤에서 자세하게 설명한다!

	```swift
	float stripe = smoothstep(1.0 - stripeHeight, 1.0, sin((time+y)/spacing));
	```
- stripe noise value를 추가한다.

	```swift
	return image+(noise*noise*stripe)+(noise*backgroundNoise);
	```

#### Wrapping in Core Image Filter
- .

```swift
	//😀 override된 `outputImage` getter는 다양한 value들이 있는 kernel을 지나가는것이 필요하다.
	let argument = [inputImage, noise, inputTime, inputSpacing, inputStripeHeight, inputBackgroundNoise]
	
	//😀 전체 이미지에 필터를 적용하기. `applyWithExtent`를 사용하기.
	let final = kernel.applyWithExtent(inputImage.extent, arguments: arguments)?.imageByApplyingFilter("CIPhotoEffectNoir", withInputParameters:nil)
```

## Pseudocolor with Mix & Smoothstep
#### Introduction
- pseudocolor filter의 기본처럼 작동할 kernel을 만드는 색 사이를 삽입하는데에 두가지 techinique를 살펴본다.
- pseudocolor image는 자신의 source와 output image에 기초를 둔 map color와 같은 monochrome(단색) image를 가진다.
- 대표적인 사용으로는 monochrome elevation map 또는 적외선 카메라의 흑백사진같은 output을 colorlize 시키는 것이다.
- inputColor0.... inputColor4와 같은 5가지 색을 만들고 inputColor0은 input image의 가장 어두운 영역으로 inputColor4는 가장 밝은 영역으로 mapping 시킨다.
	- Color 0 : Blue(0, 0, 1)
	- Color 1 : Yellow(1, 1, 0)
	- Color 2 : Black(0, 0, 0)
	- Color 3 : Green(0, 1, 0)
	- Color 4 : Red(1, 0, 0)

#### Linear Interpolation
- .

	```swift
	kernel vec4 pseudoColor(__sample pixel,
			vec4 inputColor0,
			vec4 inputColor1,
			vec4 inputColor2,
			vec4 inputColor3,
			vec4 inputColor4)
			
			
	//밝기에 따라서 색을 변하게 하기.
	vec4 luma = vec4(doc(pixel.rgb, vec3(0.2126, 0.7152, 0.0722)));
	
	// mix() 함수는 3개의 argument를 가진다. 두가지는 처음과 끝의 범위를 지정하고, 나머지 하나는 정상화 값이다.
	if luma.x < 0.25 {
		
		//0~0.25 범위에 4를 곱해주었으므로 0~1의 범위로 늘어난다.
		return mix(inputColor0, inputColor1, luma*4.0);
	}
	
	if luma.x >=0.25 && luma.x<0.5 {
		return mix(inputColor1, inputColor2, (luma-0.25)*4.0);
	}
	
	if luma.x >= 0.5 && luma.x < 0.75 {
		return mix(inputColor2, inputColor3, (luma-0.5)*4.0);
	}
	
	return mix(inputColor3, inputColor4, (luma-0.75)*4.0);
	
	```

#### Hermite Interpolation
- GLSL function들인 `mix()`와 `smoothstep()`의 차이점 : 첫번째와 두번째 argument는 edge of the interpolation, 세번째 argument는 interpolate하는 value라는 것이다.

#### Mixing Between Linear and Hermite

## Filtering Indivisual Channels
#### Introduction
- .

```swift
	kernel vec4 rgbChannelCompositing(__sample red, __sample green, __sample blue) {
		return vec4(red.r, green.g, blue.b, 1.0);
	}
	
	
	let seaside = CIImage(image: UIImage(named: "seaside.jpg")!)!
	
	let redImage = seaside.imageByAppyingFilter("CIColorControls", withInputParameters:[kCIInputContrastKey: 2.8])
	
	let greenImage = seaside.imagByApplyingFilter("CIColorControls", withInputParameters: [kCIInputContrastKey: 2.25, kCIInputBrightnessKey: 0.25])
	
	let blueImage = seaside.imageByApplyingFilteR("CIColorControls", withInputParameters:[kCIInputBrightnessKey: -0.25])
	
	let rgbCompositing = CIFilter(name : "RGBChannelCompositing", wittInputParameters: ["inputRedImage":redImage, "inputGreenImage": greenImage, "inputBlueImage":blueImage])
```

[GitHub 꼭 읽어보기!💡](https://github.com/FlexMonkey/Filterpedia/blob/master/Filterpedia/customFilters/RGBChannelCompositing.swift)

#### RGB Brightness and Contrast Filter
- r, g, b값에 각각 이미지 넣어서 합쳐 주는 방식.

```swift
class RGBChannelBrightnessAndContrast: CIFilter {
	var inputImage: CIImage?
	
	var inputRedBrightness: CGFloat = 0
	var inputRedContrast: CGFloat = 1
	
	var inputGreenBrightness: CGFloat = 0
	var inputGreenContrast: CGFloat = 1
	
	var inputBlueBrightness: CGFloat = 0
	var inputBlueContrast: CGFloat = 1
	
	override var outputImage: CIImage! {
		
		guard let inputImage = inputImage else{
			return nil
		}
		
		let red = inputImage.imageByApplyingFilter("CIColorControls", withInputParameters: [kCIInputBrightnessKey: inputRedBrightness, kCIInputContrastKey: inputRedContrast])
		
		let green = inputImage.imageByApplyingFilter("CIColorControls", withInputParameters:[kCIInputBrightnessKey: iputGreenBrightness, kCIInputContrastKey: inputGreenContrast])
		
		let blue = inputImage.imageByApplyingFilter("CIColorControls", withInputParameters:[kCIInputBrightnessKey: inputBlueBrightness, kCIInputContrastKey: inputBlueContrast])
		
		rgbChannelCompositing.inputRedImage = red
		rgbChannelCompositing.inputGreenImage = green
		rgbChannelCompositing.inputBlueImage = blue
		
		let finalImage = rgbChannelCompositing.outputImage
		
		return finalImage
	}

}
```

- 한 번에 각각 argument 지정해주는 방식

	```swift
		let treatedSeaside = seaside.imageByApplyingFilter("RGBChannelBrightnessAndContrast", withInputParameters: ["inputRedContrast": 2.8, "inptGreenContrast": 2.25, "inputGreenBrightness": 0.25, "inputBlueBrightness": 0.-25])
	```

#### RGB Tone Curve Filter
- 포토샵에서 처럼 r, g, b 각각의 그래프를 조정하여 각 값의 명도와 대비를 조정.
- `CIToneCurve` :  r, g, b값 상관없이 input image 자체의 곡선 그래프를 조정.
- `RGBChannelBrightnessAndContrast` & `CIToneCurve` : 분리된 tone curve를 각각의 color channel로.

	```swift
	var inputRedValue = CIVector(values:[0.0, 0.25, 0.5, 0.75, 1.0], count:5)
	var inputGreenValue = CIVector(values:[0.0, 0.25, 0.5, 0.75, 1.0], count:5)
	var inputBlueValue = CIVector(values: [0.0, 0.25, 0.5, 0.75, 1.0], count:5)
	
	let red = inputImageByApplyingFilter("CIToneCurve", withInputParameters: [
																				"inputPoint0" : CIVector(x:0.0, y: inputRedValues.valueAtIndex(0)), 
																				"inputPoint1" : CIVector(x:0.25, y: inputRedValues.valueAtIndex(1)), 
																				"inputPoint2" : CIVector(x:0.5, y:inputRedValues.valueAtIndex(2)),
																				"inputPoint3" : CIVector(x:0.75, y:inputRedValues.valueAtIndex(3)),
																				"inputPoint4" : CIVector(x: 1.0, y: inputRedValues.valueAtIndex(4))
	])
	
	let blue = ....
	let green = ....
	
	let rgbChannelCompositing = RGBChannelCompositing()
	rgbChannelCompositing.inputRedImage = red
	rgbChannelCompositing.inputBlueImage = blue
	rgbChannelCompositing.inputGreenImage = green
	
	return rgbChannelCompositing.outputImage
	```

#### RGB Gaussian Blur
- green channel만 blur.

	```swift
	var inputRedRadius: CGFloat = 2
	var inputGreenRadius: CGFloat = 4
	var inputBlueRadius: CGFloat = 8
	
	override var outputImage: CGImage! {
	
		guard let inputImage = inputImage else {
			return nil
		}
		
		let red = inputImage.imageByApplyingFilter("CIGaussianBlur", withInputParameters: [kCIInputRadiusKey: inputRedRadius]).imageByClampingToExtent()
		let green = inputImage.imageByApplyingFilter("CIGaussianBlur", withInputParameters: [kCIInputRadiusKey: inputGreenRadius]).imageByClampingToExtent()
		let blue = inputImage.imageByApplyingFilter("CIGaussianBlur", withInputParameters: [kCIInputRadiusKey: inputBlueRadius]).imageByClampingToExtent()
		
		let rgbChannelCompositing = RGBChannelCompositing()
		
		rgbChannelCompositing.inputRedImage = red
		rgbChannelCompoisiting.inputGreenImage = green
		rgbChannelCompositing.inputBlurImage = blue
		
		return rgbChannelCompositing.outputImage
		
	}
	
	```

#### Chromatic Aberration
- .

```swift
var inputAngle: CGFloat = 0
var inputRadius: CGFloat = 2

override var outputImage:CGImage! {
	
	//tou는 2파이로 정의된다.
	let redAngle = inputAngle + tou
	let greenAngle = inputAngle + tou*0.333
	let blueAngle = inputAngle + tou*0.666
	
	
	let redTransform = CGAffineTransformMakeTranslation(
		sin(redAngle) * inputRadius,
		cos(redAngle) * inputRadius)
		
	let greenTransform = CGAffineTransformMakeTranslation(
		sin(greenAngle) * inputRadius,
		cos(greenAngle) * inputRadius)
		
	let blueTransform = CGAffineTransformMakeTranslation(
		sin(blueAngle) * inputRadius,
		cos(blueAngle) * inputRadius)
		
		
	let red = inputImage.imageByApplyingFilter("CIAffineTransform, withInputParameters: [kCIInputParameters: [kCIInputTransformKey: NSValue(CGAffineTransform: redTransform)]).imageByCroppingToRect(inputImage.extent)
	let green = inputImage.imageByApplyingFilter("CIAffineTransform, withInputParameters: [kCIInputParameters: [kCIInputTransformKey: NSValue(CGAFffineTransform: greenTransform)]).imageByCroppingToRect(inputImage.extent)
	let blue = inputImage.imageByApplyingFilter("CIAffineTransform, withInputParameters: [kCIInputParameters: [kCIInputTrnasformKey: NSValue(CGAffineTransform: bluTransform)]).imageByCroppingToRect(inputImage.extent)
	
	let rgbChannelCompositing = RGBChannelCompositing()
	
	rgbChannelCompositing.inputRedImage = red
	rgbChannelCompositing.inputGreenImage = green
	rgbChannelCompositing.inputBlueImage = blue
	
	return finalImage = rgbChannelCompositing.outputImage
}
```

## Color Map Filter Revisited
#### Creating an Eight Bit Filter
- .

```swift
    static let appleIIColors = [
        RGB(r: 0, g: 0, b: 0),
        RGB(r: 114, g: 38, b: 64),
        RGB(r: 64, g: 51, b: 127),
        RGB(r: 228, g: 52, b: 254),
        RGB(r: 14, g: 89, b: 64),
        RGB(r: 128, g: 128, b: 128),
        RGB(r: 27, g: 154, b: 254),
        RGB(r: 191, g: 179, b: 255),
        RGB(r: 64, g: 76, b: 0),
        RGB(r: 228, g: 101, b: 1),
        RGB(r: 128, g: 128, b: 128),
        RGB(r: 241, g: 166, b: 191),
        RGB(r: 27, g: 203, b: 1),
        RGB(r: 191, g: 204, b: 128),
        RGB(r: 141, g: 217, b: 191),
        RGB(r: 255, g: 255, b: 255)
    ]
    
    override var outputImage:CGImage? {
    	let paletteIndex = max(min(EightBit.palettes.count-1, Int(inputPaletteIndex)), 0)
    	let palette = EightBit.palettes[paletteIndex]
    	
    	//color kernel! every color's every pixel의 거리를 의미.
    	
        var kernelString = "kernel vec4 thresholdFilter(__sample image)"
        	kernelString += "{ \n"
        	kernelString += "   vec2 uv = samplerCoord(image); \n"
        	kernelString += "   float dist = distance(image.rgb, \(palette.first!.toVectorString())); \n"
        	kernelString += "   vec3 returnColor = \(palette.first!.toVectorString());\n "
        	
        kernel vec4 thresholdFilter(__sample image){
        	vec2 uv = samplerCoord(image);
        	float dist = distance(image.rgb, vec3(0.0, 0.0, 0.0)));
        	vec3 returnColor = vec3(0.0, 0.0, 0.0);
        }
        	
        for paletteColor in palette where paletteColor != palette.first!
        {
            kernelString += "if (distance(image.rgb, \(paletteColor.toVectorString())) < dist) \n"
            kernelString += "{ \n"
            kernelString += "   dist = distance(image.rgb, \(paletteColor.toVectorString())); \n"
            kernelString += "   returnColor = \(paletteColor.toVectorString()); \n"
            kernelString += "} \n"
        }        	
        
        if distance(image.rgb, vec3(0.44, 0.14, 0.25)) < dist {
        	dist = distance(image.rgb, vec3(0.44, 0.14, 0.25));
        	returnColor = vec3(0.44, 0.14, 0.25);
        }
        
        if distance(image.rgb, vec3(0.25, 0.2, 0.49)) < dist {
        	dist = distance(image.rgb, vec3(0.25, 0.2, 0.49));
        	returnColor = vec3(0.25, 0.2, 0.49);
        }
        
        let extent = inputImage.extent
        let pixellatedImage = inputImage.imageByApplyingFilter("CIPixellate", withInputParameters: [kCIInputScaleKey: inputScale])
        
        let final = kernel.applyWithExtent(extent, arguments: [pixellatedImage])
        
        return final
    }
    
```

[github code](https://github.com/FlexMonkey/Filterpedia/blob/master/Filterpedia/customFilters/EightBit.swift)

## Setting Extent for Color Kernels
#### Single Image Color Kernels
- .

```swift
//RedGreenFilter
kernel vec4 thresholdFilter(__sample image) {
	return vec4(image.r, image.g*0.5, 0.0, image.a);
}

//BlueGreenFilter
kernel vec4 thresholdFilter(__sample image){
	return vec4(0.0, image.g*0.5, image.b, image.a);
}

override var outputImage :CIImage! {
	guard let inputImage = inputImage, kernel = kernel else{
		return nil
	}
	
	let extent = self.extent ?? inputImage.extent
	
	let argument = [inputImage]
	
	return kernel.applyWithExtent(extent, arguments: arguments)
}

let blueGreenFilter= BlueGreenFilter()
bluegreenFilter.inputImage = sunflower
bluegreenFilter.extent = sunflower.extent.insetBy(dx:0, dy:200)
let blueGreenOutput = bluegreenFilter.outputImage

```

#### Composite Image Color Kernels, 합성사진 color kernel